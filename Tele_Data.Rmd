---
title: "HW6 Telemarketing"
author: "Group 6 # Pentagon"
date: "3/28/2020"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Logistic Regression

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```


## Getting Train and Test Samples

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))] #KNN likes the rows seperate

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"] #seperating yyes as a seperate data for KNN

# data for LG
tele_train_lg <-tele_norm[-test_set,]
tele_test_lg <-tele_norm[test_set,]
```

## Build model LG
```{r, cache= TRUE}
model1 <- glm(yyes ~ ., data = tele_train_lg, family = "binomial")
summary(model1)
```

## Predict Model
```{r, cache= TRUE}
model1pred <-predict(model1, tele_test_lg, type="response")
summary(model1pred)
model1success <- ifelse(model1pred >= 0.25, 1,0)
summary(model1success)
table(model1success)
```

## Evaluate Model LG
```{r, cache=TRUE}
library(caret)
confusionMatrix(as.factor(model1success), as.factor(tele_test_lg$yyes),positive = "1")
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```

#KNN

## Getting Train and Test Samples

```{r, cache=TRUE}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]

```

> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.

## Build model
```{r, cache=TRUE}
library(class)
tele_model <- knn(tele_train, tele_test, tele_train_labels, k=4) 
#Here our n is 31189, so take sqrt(31189)
```

## Evaluate model
```{r, cache=TRUE}
library(caret)
#Create confusion matrix
confusionMatrix(as.factor(tele_model), as.factor(tele_test_labels), positive ="1")
```

#ANN

```{r, cache=TRUE}
## Test and Train
set.seed(12345)
test_rows <- sample(1:nrow(tele_norm), 0.2*nrow(tele_norm))
tele_test <- tele_norm[test_rows,]
tele_train <- tele_norm[-test_rows,]

```

## Build model 
```{r, cache=TRUE}
library(neuralnet)

simplemodel <- neuralnet( yyes ~ ., data = tele_train, hidden = 1) #first parameter (y parameter)
plot(simplemodel)
```
## Predict Test

```{r, cache=TRUE}
simplepred <- predict(simplemodel, tele_test)
summary(simplepred)

simplebin <- ifelse(simplepred >= 0.5, 1, 0)

library(caret)
confusionMatrix(as.factor(simplebin), as.factor(tele_test$yyes), positive = "1")
```

## Medium complexity model

```{r}
#midmodel <- neuralnet(yyes ~ ., data = tele_train, hidden = 5)#first parameter (y parameter)
#plot(midmodel)

#midpred <- predict(midmodel, tele_test)
#summary(midpred)

#midbin <- ifelse(midpred >= 0.5, 1, 0)

#library(caret)
#confusionMatrix(as.factor(midbin), as.factor(tele_test$yyes), positive = "1")
```

# Combine predictions using majority voting
```{r, cache=TRUE}
combined_preds <- numeric(length(model1pred))
for (i in 1:length(model1pred)) {
  count <- sum(c(model1pred[i], tele_model[i], simplebin[i]))
  if (count >= 2) {
    combined_preds[i] <- 1
  } else {
    combined_preds[i] <- 0
  }
}

```

